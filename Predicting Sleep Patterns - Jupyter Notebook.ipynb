{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "254a4692",
      "metadata": {
        "id": "254a4692"
      },
      "source": [
        "\n",
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "9a221e0b",
      "metadata": {
        "id": "9a221e0b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173c02b7",
      "metadata": {
        "id": "173c02b7"
      },
      "source": [
        "\n",
        "## Preparing The Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "3e2c01db",
      "metadata": {
        "id": "3e2c01db"
      },
      "outputs": [],
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.data['University_Year'] = self.data['University_Year'].str[0].astype(int)\n",
        "        self.features = self.data.drop(columns=['Student_ID', 'Gender', 'Sleep_Duration', 'Sleep_Quality',\n",
        "                                                'Weekday_Sleep_Start', 'Weekday_Sleep_End', 'Weekend_Sleep_Start',\n",
        "                                                'Weekend_Sleep_End'])\n",
        "        self.labels = self.data['Sleep_Duration']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the sample and corresponding label\n",
        "        sample = torch.tensor(self.features.iloc[idx].values, dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels.iloc[idx], dtype=torch.float32)\n",
        "        return sample, label\n",
        "\n",
        "Sleep = MyData('/content/student_sleep_patterns.csv')\n",
        "\n",
        "# Divinding the data into training, validation and test sets\n",
        "train_size = int(0.8 * len(Sleep))              # 80%\n",
        "val_size = int(0.1 * len(Sleep))                # 10%\n",
        "test_size = len(Sleep) - train_size - val_size  # 10%\n",
        "train_data, val_data, test_data = random_split(Sleep, [train_size, val_size, test_size])\n",
        "\n",
        "# Further dividing the sets into mini-batches\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9348b409",
      "metadata": {
        "id": "9348b409"
      },
      "source": [
        "\n",
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "id": "1134e1ba",
      "metadata": {
        "id": "1134e1ba"
      },
      "outputs": [],
      "source": [
        "class MyNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(6, 80)          # Input layer (6 features per sample)\n",
        "        self.fc2 = nn.Linear(80, 50)         # Hidden layer 1 (80 neurons)\n",
        "        self.fc3 = nn.Linear(50, 1)          # Hidden layer 2 (50 neurons) - Outputs a scalar\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = MyNN()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
        "epochs = 150\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()                         # Sets model to training mode\n",
        "    running_loss = 0\n",
        "\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()             # Resets gradient values\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    average_loss = running_loss / train_size\n",
        "    #print(average_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f903c191",
      "metadata": {
        "id": "f903c191"
      },
      "source": [
        "\n",
        "## Runnning the Model on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "id": "71dd0569",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71dd0569",
        "outputId": "fea4ad35-6b64-43ec-ce31-97f40c2ac581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage differences: 25.736026763916016\n"
          ]
        }
      ],
      "source": [
        "def evaluation(loader):\n",
        "    model.eval()                   # Sets model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():          # Disables gradient calculations\n",
        "        for features, labels in loader:\n",
        "          output = model(features)\n",
        "          batch_percentage_diff = ((labels - output).abs() / labels) * 100\n",
        "          avg_batch_percentage_diff = batch_percentage_diff.mean().item()\n",
        "    return avg_batch_percentage_diff\n",
        "\n",
        "percentage_differences = evaluation(val_loader)\n",
        "print(f'Percentage differences: {percentage_differences}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf8f45bf",
      "metadata": {
        "id": "cf8f45bf"
      },
      "source": [
        "\n",
        "## Runnning the Model on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "id": "861a32cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "861a32cf",
        "outputId": "1c1398be-583b-47e1-ccbb-a34126944b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage differences: 20.480247497558594\n"
          ]
        }
      ],
      "source": [
        "percentage_differences = evaluation(test_loader)\n",
        "print(f'Percentage differences: {percentage_differences}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}